ç®€ä½“ä¸­æ–‡ | [English](README.md)

# RT-DETR 

æ–‡ç« "[DETRs Beat YOLOs on Real-time Object Detection](https://arxiv.org/abs/2304.08069)"å’Œ"[RT-DETRv2: Improved Baseline with Bag-of-Freebies for Real-Time Detection Transformer](https://arxiv.org/abs/2407.17140)"çš„å®˜æ–¹å®ç°.

<details>
<summary>Fig</summary>

<div align="center">
  <img src="https://github.com/lyuwenyu/RT-DETR/assets/77494834/0ede1dc1-a854-43b6-9986-cf9090f11a61" width=500 >
</div>

</details>


## æœ€æ–°åŠ¨æ€
- å‘å¸ƒRT-DETRv2ç³»åˆ—æ¨¡å‹
- å‘å¸ƒRT-DETR-R50, RT-DETR-R101æ¨¡å‹
- å‘å¸ƒRT-DETR-R50-mæ¨¡å‹ï¼ˆscaleæ¨¡å‹çš„èŒƒä¾‹ï¼‰
- å‘å¸ƒRT-DETR-R34, RT-DETR-R18æ¨¡å‹
- å‘å¸ƒRT-DETR-L, RT-DETR-Xæ¨¡å‹


## ä»£ç ä»“åº“
- ğŸ”¥ RT-DETRv2
  - paddle: [code&weight](./rtdetrv2_paddle/)
  - pytorch: [code&weight](./rtdetrv2_pytorch/)
- ğŸ”¥ RT-DETR 
  - paddle: [code&weight](./rtdetr_paddle)
  - pytorch: [code&weight](./rtdetr_pytorch)


## ç®€ä»‹
<!-- We propose a **R**eal-**T**ime **DE**tection **TR**ansformer (RT-DETR), the first real-time end-to-end object detector to our best knowledge. Specifically, we design an efficient hybrid encoder to efficiently process multi-scale features by decoupling the intra-scale interaction and cross-scale fusion, and propose IoU-aware query selection to improve the initialization of object queries. In addition, our proposed detector supports flexibly adjustment of the inference speed by using different decoder layers without the need for retraining, which facilitates the practical application of real-time object detectors. Our RT-DETR-L achieves 53.0% AP on COCO val2017 and 114 FPS on T4 GPU, while RT-DETR-X achieves 54.8% AP and 74 FPS, outperforming all YOLO detectors of the same scale in both speed and accuracy. Furthermore, our RT-DETR-R50 achieves 53.1% AP and 108 FPS, outperforming DINO-Deformable-DETR-R50 by 2.2% AP in accuracy and by about 21 times in FPS.  -->
RT-DETRæ˜¯ç¬¬ä¸€ä¸ªå®æ—¶ç«¯åˆ°ç«¯ç›®æ ‡æ£€æµ‹å™¨ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªé«˜æ•ˆçš„æ··åˆç¼–ç å™¨ï¼Œé€šè¿‡è§£è€¦å°ºåº¦å†…äº¤äº’å’Œè·¨å°ºåº¦èåˆæ¥é«˜æ•ˆå¤„ç†å¤šå°ºåº¦ç‰¹å¾ï¼Œå¹¶æå‡ºäº†IoUæ„ŸçŸ¥çš„æŸ¥è¯¢é€‰æ‹©æœºåˆ¶ï¼Œä»¥ä¼˜åŒ–è§£ç å™¨æŸ¥è¯¢çš„åˆå§‹åŒ–ã€‚æ­¤å¤–ï¼ŒRT-DETRæ”¯æŒé€šè¿‡ä½¿ç”¨ä¸åŒçš„è§£ç å™¨å±‚æ¥çµæ´»è°ƒæ•´æ¨ç†é€Ÿåº¦ï¼Œè€Œä¸éœ€è¦é‡æ–°è®­ç»ƒï¼Œè¿™æœ‰åŠ©äºå®æ—¶ç›®æ ‡æ£€æµ‹å™¨çš„å®é™…åº”ç”¨ã€‚RT-DETR-R50åœ¨COCO val2017ä¸Šå®ç°äº†53.1%çš„APï¼Œåœ¨T4 GPUä¸Šå®ç°äº†108FPSï¼ŒRT-DETR-R101å®ç°äº†54.3%çš„APå’Œ74FPSï¼Œåœ¨é€Ÿåº¦å’Œç²¾åº¦æ–¹é¢éƒ½ä¼˜äºç›¸åŒè§„æ¨¡çš„æ‰€æœ‰YOLOæ£€æµ‹å™¨ã€‚ä½¿ç”¨Objects365é¢„è®­ç»ƒä¹‹å, RT-DETR-R50 å’Œ RT-DETR-R101 åˆ†åˆ«å®ç°äº† 55.3% å’Œ 56.2% APçš„ç²¾åº¦.
è‹¥è¦äº†è§£æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚è€ƒæˆ‘ä»¬çš„è®ºæ–‡[paper](https://arxiv.org/abs/2304.08069).

<div align="center">
  <img src="https://github.com/lyuwenyu/RT-DETR/assets/77494834/c211a164-ddce-4084-8b71-fb73f29f363b" width=500 >
</div>

## å¼•ç”¨RT-DETR
å¦‚æœéœ€è¦åœ¨ä½ çš„ç ”ç©¶ä¸­ä½¿ç”¨RT-DETRï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š
```
@misc{lv2023detrs,
      title={DETRs Beat YOLOs on Real-time Object Detection},
      author={Yian Zhao and Wenyu Lv and Shangliang Xu and Jinman Wei and Guanzhong Wang and Qingqing Dang and Yi Liu and Jie Chen},
      year={2023},
      eprint={2304.08069},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{lv2024rtdetrv2improvedbaselinebagoffreebies,
      title={RT-DETRv2: Improved Baseline with Bag-of-Freebies for Real-Time Detection Transformer}, 
      author={Wenyu Lv and Yian Zhao and Qinyao Chang and Kui Huang and Guanzhong Wang and Yi Liu},
      year={2024},
      eprint={2407.17140},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.17140}, 
}
```
